{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020,2024 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Disease Tracking Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template for your DIY Disease Tracking Dashboard, to which you can add the code you developed in the previous notebooks. The dashboard will be displayed using [voila](https://voila.readthedocs.io/en/stable/index.html), a Python dashboarding tool that converts notebooks to standalone dashboards. Contrary to the other libraries we have seen, the ```voila``` package must be installed using *pip* or *conda* but it does not need to be imported - it rather acts at the level of the notebook server. Package ```voila``` is already installed on the QMUL JupyterHub as well as in the Binder - to install it locally, follow the [instructions](https://voila.readthedocs.io/en/stable/install.html) online.\n",
    "\n",
    "Broadly speaking, Voila acts by **running all the cells in your notebook** when the dashboard is first loaded; it then hides all code cells and displays all markdown cells and any outputs, including widgets. However, the code is still there in the background and handles any interaction with the widgets. To view this dashboard template rendered in Voila click [here](https://mybinder.org/v2/gh/fsmeraldi/diy-covid19dash/main?urlpath=%2Fvoila%2Frender%2FDashboard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial data from disk\n",
    "\n",
    "You should include \"canned\" data in ```.json``` files along with your dashboard. When the dashboard starts, it should load that data and assign it as a dictionary to the ```jsondata``` variable (the code below will be hidden when the dashboard is rendered by Voila)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "jsondata={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the data\n",
    "\n",
    "The dashboard should contain the logic to wrangle the raw data into a ```DataFrame``` (or more than one, as required) that will be used for plotting. The wrangling code should be put into a function and called on the data from the JSON file (we'll need to call it again on any data downloaded from the API).  In this template, we just pretend we are wrangling ```rawdata``` and instead generate a dataframe with some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def wrangle_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    df=pd.DataFrame(index=range(0,100), columns=['One', 'Two'])\n",
    "    # we have no real data to wrangle, so we just generate two random walks.\n",
    "    one=two=0.0\n",
    "    for i in range(0,100):\n",
    "        df.loc[i,'One']=one\n",
    "        df.loc[i,'Two']=two\n",
    "        one+=np.random.randn()\n",
    "        two+=2*np.random.randn()\n",
    "    return df\n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n",
    "df=wrangle_data(jsondata) # df is the dataframe for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your users an option to refresh the dataset - a \"refresh\" button will do. The button callback should\n",
    "* call the code that accesses the API and download some fresh raw data;\n",
    "* wrangle that data into a dataframe and update the corresponding (global) variable for plotting (here, ```df```);\n",
    "* optionally: force a redraw of the graph and give the user some fredback.\n",
    "\n",
    "Once you get it to work, you may want to wrap your API call inside an exception handler, so that the user is informed, the \"canned\" data are not overwritten and nothing crashes if for any reason the server cannot be reached or data are not available.\n",
    "\n",
    "After you refresh the data, graphs will not update until the user interacts with a widget. You can trick ```iPywidgets``` into redrawing the graph by simulating interaction, as in the ```refresh_graph``` function we define in the Graph and Analysis section below.\n",
    "\n",
    "In this example, clicking on the button below just generates some more random data and refreshes the graph. The button should read *Fetch Data*. If you see anything else, take a deep breath :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the UKHSA API. Return data as a like-for-like replacement for the \"canned\" data loaded from the JSON file. \"\"\"\n",
    "    return {} # return data read from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "    apidata=access_api()\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "    global df\n",
    "    df=wrangle_data(apidata)\n",
    "    # the graph won't refresh until the user interacts with the widget.\n",
    "    # this function simulates the interaction, see Graph and Analysis below.\n",
    "    # The function needs to be adapted to your graph; you can omit this call\n",
    "    # in the first instance\n",
    "    refresh_graph()\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. If you are \n",
    "    # implementing error handling, you can use icons \"unlink\" or \"times\" and \n",
    "    # change the button text to \"Unavailable\" when the api call fails.\n",
    "    apibutton.icon=\"check\"\n",
    "    # apibutton.disabled=True\n",
    "\n",
    "    \n",
    "apibutton=wdg.Button(\n",
    "    description='PANIC', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Keep calm and carry on\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='exclamation-triangle'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "display(apibutton)\n",
    "\n",
    "# run all cells before clicking on this button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include at least one graph with interactive controls, as well as some instructions for the user and/or comments on what the graph represents and how it should be explored (this example shows two random walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_walk(walk):\n",
    "    \"\"\" Our sample graph plotting function \"\"\"\n",
    "    df[walk].plot()\n",
    "    plt.show() # important! update won't work properly without this\n",
    "\n",
    "# a sample widget\n",
    "whichwalk=wdg.Dropdown(\n",
    "    options=['One', 'Two'],\n",
    "    value='One',\n",
    "    description='Walk no: ',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "    current=whichwalk.value\n",
    "    if current==whichwalk.options[0]:\n",
    "        other=whichwalk.options[1]\n",
    "    else:\n",
    "        other=whichwalk.options[0]\n",
    "    whichwalk.value=other # forces the redraw\n",
    "    whichwalk.value=current # now we can change it back\n",
    "    \n",
    "# connect the plotting function and the widget    \n",
    "graph=wdg.interactive_output(plot_random_walk, {'walk': whichwalk})\n",
    "\n",
    "# actually displays the graph\n",
    "display(whichwalk, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the dashboard\n",
    "\n",
    "Once your code is ready and you are satisfied with the appearance of the graphs, replace all the text boxes above with the explanations you would like a dashboard user to see. The next step is deploying the dashboard online - there are several [options](https://voila.readthedocs.io/en/stable/deploy.html) for this, we suggest deploying as a [Binder](https://mybinder.org/). This is basically the same technique that has been used to package this tutorial and to deploy this template dashboard. The instructions may seem a bit involved, but the actual steps are surprisingly easy - we will be going through them together during a live session. You will need an account on [GitHub](https://github.com/) for this - if you don't have one already, now it's the time to create it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author and License** Remember that if you deploy your dashboard as a Binder it will be publicly accessible. Change the copyright notice and take credit for your work! Also acknowledge your sources and the conditions of the license by including this notice: \"Based on UK Government [data](https://ukhsa-dashboard.data.gov.uk/) published by the [UK Health Security Agency](https://www.gov.uk/government/organisations/uk-health-security-agency) and on the [DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) by Fabrizio Smeraldi. Released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "    \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure={\"theme\": \"infectious_disease\", \n",
    "           \"sub_theme\": \"respiratory\",\n",
    "           \"topic\": \"COVID-19\",\n",
    "           \"geography_type\": \"Nation\", \n",
    "           \"geography\": \"England\"}\n",
    "\n",
    "structure[\"metric\"] = \"COVID-19_cases_casesByDay\"\n",
    "\n",
    "filters={\"stratum\" : None, # Smallest subgroup a metric can be broken down into e.g. ethnicity, testing pillar\n",
    "         \"age\": None, # \n",
    "         \"sex\": None, #  \n",
    "         \"year\": 2020, #  Epi year of the metrics value (important for annual metrics) e.g. 2020\n",
    "         \"month\": None, # Epi month of the metric value (important for monthly metrics) e.g. 12\n",
    "         \"epiweek\" :None, # Epi week of the metric value (important for weekly metrics) e.g. 30\n",
    "         \"date\" : None, # \n",
    "         \"in_reporting_delay_period\": None # Boolean indicating whether the data point is considered to be subject to retrospective updates\n",
    "        }\n",
    "\n",
    "api = APIwrapper(**structure)\n",
    "cases_data_20 = api.get_all_pages(filters)\n",
    "print(api.count)#gives 337 - Covid didnt arrive to Britain until late January\n",
    "#print(cases_data_20)\n",
    "\n",
    "import json \n",
    "with open(\"cases2020.json\", \"wt\") as OUTF:\n",
    "    json.dump(cases_data_20, OUTF)\n",
    "\n",
    "\n",
    "filters={\"stratum\" : None, # Smallest subgroup a metric can be broken down into e.g. ethnicity, testing pillar\n",
    "         \"age\": None, # \n",
    "         \"sex\": None, #  \n",
    "         \"year\": 2022, #  Epi year of the metrics value (important for annual metrics) e.g. 2020\n",
    "         \"month\": None, # Epi month of the metric value (important for monthly metrics) e.g. 12\n",
    "         \"epiweek\" :None, # Epi week of the metric value (important for weekly metrics) e.g. 30\n",
    "         \"date\" : None, # \n",
    "         \"in_reporting_delay_period\": None # Boolean indicating whether the data point is considered to be subject to retrospective updates\n",
    "        }\n",
    "cases_data_22 = api.get_all_pages(filters)\n",
    "print(api.count) #gives 365 as there are 365 items - cases everyday for 2022\n",
    "#print(cases_data_22)\n",
    "\n",
    "import json \n",
    "with open(\"cases2022.json\", \"wt\") as OUTF1:\n",
    "    json.dump(cases_data_22, OUTF1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import json\n",
    "\n",
    "with open(\"cases2020.json\", \"rt\") as INFILE:\n",
    "    cases20=json.load(INFILE)\n",
    "    \n",
    "with open(\"cases2022.json\", \"rt\") as INFILE:\n",
    "    cases22=json.load(INFILE)\n",
    "\n",
    "#cases20[:3]\n",
    "\n",
    "dataset1={} #here we go through each entry in each dataset to create a new dictionary with just the entry dates and the metrics and metric values {date:{metric:metric values}}\n",
    "for dataset in [cases20]:\n",
    "    for entry in dataset:\n",
    "        date=entry['date']\n",
    "        metric=entry['metric']\n",
    "        value=entry['metric_value']\n",
    "        if date not in dataset1:\n",
    "            dataset1[date]={}\n",
    "            dataset1[date][metric]=value\n",
    "\n",
    "#print(dataset1)\n",
    "\n",
    "dates=list(dataset1.keys()) # the keys are the date, as created in the for loop above\n",
    "dates.sort() #sorted them in order - they probably were already but just to be sure\n",
    "#print(dates)\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\") #using pandas to convert our dates into a nice string\n",
    "\n",
    "startdate=parse_date(dates[0])\n",
    "enddate=parse_date(dates[-1])\n",
    "print (startdate, ' to ', enddate) # we will use this data range for our data frame\n",
    "\n",
    "index=pd.date_range(startdate, enddate) #building our data frame - it is empty and we must put in the data\n",
    "firstdf=pd.DataFrame(index=index, columns=['Cases'])\n",
    "#print(firstdf)\n",
    "\n",
    "metrics = {'Cases':'COVID-19_cases_casesByDay'}\n",
    "\n",
    "for date,entry in dataset1.items(): #remember dataset1 is {date:{metric:metric values}}\n",
    "    pd_date = parse_date(date) #converts our dates into pandas format\n",
    "    for column in ['Cases']:\n",
    "        metric_name=metrics[column]\n",
    "        # do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "        value= entry.get(metric_name, 0.0)\n",
    "        # this is the way you access a specific location in the dataframe - use .loc\n",
    "        # and put index,column in a single set of [ ]\n",
    "        firstdf.loc[date, column]=value\n",
    "\n",
    "            \n",
    "# fill in any remaining \"holes\" due to missing dates\n",
    "firstdf.fillna(0.0, inplace=True)\n",
    "            \n",
    "\n",
    "print(firstdf)\n",
    "\n",
    "first_graph = firstdf.plot(color = 'navy')\n",
    "first_graph.set_title(\"COVID-19 INCIDENCE: 2020\", size = 20)\n",
    "first_graph.set_ylabel('No. of cases', size = 16)\n",
    "\n",
    "#The Python code iterates through a dictionary dataset1\n",
    "#extracts \"Cases\" data for each date, populates a Pandas DataFrame named firstdf with this data, \n",
    "#and handles any missing values by replacing them with 0.0. \n",
    "#Finally, it generates and displays a line plot of the \"Cases\" data over time, with the title \"Covid-19 Prevalence: 2020\"\n",
    "\n",
    "firstdf.to_pickle(\"firstdf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as wdg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "cases20=pd.read_pickle(\"firstdf.pkl\")\n",
    "cases21=pd.read_pickle(\"2021.pkl\")\n",
    "cases22=pd.read_pickle(\"2022.pkl\")\n",
    "\n",
    "# --- make sure indexes are datetime ---\n",
    "cases20.index = pd.to_datetime(cases20.index)\n",
    "cases21.index = pd.to_datetime(cases21.index)\n",
    "cases22.index = pd.to_datetime(cases22.index)\n",
    "\n",
    "# --- year selector widget ---\n",
    "year = wdg.Select(\n",
    "    options=[2020,2021,2022],\n",
    "    value=2020,\n",
    "    rows=1,\n",
    "    description='Year',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "scale = wdg.ToggleButtons(\n",
    "    options=['linear', 'log'],\n",
    "    value='linear',\n",
    "    description='Scale:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# --- callback function ---\n",
    "def cases_graph(graphyear, gscale):\n",
    "    if graphyear == 2020:\n",
    "        yeardf1 = cases20\n",
    "    elif graphyear == 2021:\n",
    "        yeardf1 = cases21\n",
    "    elif graphyear == 2022:\n",
    "        yeardf1 = cases22\n",
    "    else:\n",
    "        return  # just in case\n",
    "\n",
    "    logscale = (gscale == 'log')\n",
    "    \n",
    "    color_map = {2020:'navy', 2021: 'blue', 2022: 'cyan'}\n",
    "    color = color_map.get(graphyear)\n",
    "    first_graph = yeardf1.plot(color = color, logy = logscale)\n",
    "    first_graph.set_title(f\"COVID-19 INCIDENCE: {graphyear}\", size = 20)\n",
    "    first_graph.set_ylabel('No. of cases', size = 16)\n",
    "    plt.show()\n",
    "    \n",
    " # must be inside the function!\n",
    "\n",
    "# --- interactive output ---\n",
    "output = wdg.interactive_output(cases_graph, {'graphyear': year,'gscale' : scale})\n",
    "#display(year,controls, output)\n",
    "\n",
    "display(year,scale,output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
